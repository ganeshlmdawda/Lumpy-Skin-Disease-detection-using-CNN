{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3XfvYVXzXyg",
        "outputId": "4638b40c-7eae-4327-b0e4-f7b918daad40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K67pR3BKU5XI",
        "outputId": "0a393b75-9cc2-4654-924d-8abfb72178e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va-od6EJ68iW",
        "outputId": "ec61717a-0eee-4cbf-bdd3-f9be698da1e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydot\n",
        "!pip install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6sWokv_qXVJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfVdDjQIVkcq",
        "outputId": "3b110768-a087-48a7-80b6-342a334687ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             image_path    label\n",
            "0     /content/drive/MyDrive/Lumpy_Skin_Disease/Data...    Lumpy\n",
            "1     /content/drive/MyDrive/Lumpy_Skin_Disease/Data...    Lumpy\n",
            "2     /content/drive/MyDrive/Lumpy_Skin_Disease/Data...    Lumpy\n",
            "3     /content/drive/MyDrive/Lumpy_Skin_Disease/Data...    Lumpy\n",
            "4     /content/drive/MyDrive/Lumpy_Skin_Disease/Data...    Lumpy\n",
            "...                                                 ...      ...\n",
            "1138  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "1139  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "1140  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "1141  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "1142  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "\n",
            "[1143 rows x 2 columns]\n",
            "                                            image_path  label\n",
            "0    /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Lumpy\n",
            "1    /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Lumpy\n",
            "2    /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Lumpy\n",
            "3    /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Lumpy\n",
            "4    /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Lumpy\n",
            "..                                                 ...    ...\n",
            "386  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Lumpy\n",
            "387  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Lumpy\n",
            "388  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Lumpy\n",
            "389  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Lumpy\n",
            "390  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Lumpy\n",
            "\n",
            "[391 rows x 2 columns]\n",
            "                                            image_path    label\n",
            "0    /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "1    /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "2    /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "3    /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "4    /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "..                                                 ...      ...\n",
            "747  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "748  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "749  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "750  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "751  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy\n",
            "\n",
            "[752 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Paths to directories containing the images\n",
        "lumpy_dir_path = '/content/drive/MyDrive/Lumpy_Skin_Disease/Dataset/Lumpy Skin'  # Replace with your actual path\n",
        "healthy_dir_path = '/content/drive/MyDrive/Lumpy_Skin_Disease/Dataset/Normal Skin'  # Replace with your actual path\n",
        "\n",
        "# Function to load images and labels into a DataFrame\n",
        "def load_images_labels(dir_path, label):\n",
        "    \"\"\"Load image paths and labels from the specified directory.\"\"\"\n",
        "    images = []\n",
        "    for filename in os.listdir(dir_path):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\")):  # Add or modify the file types as needed\n",
        "            image_path = os.path.join(dir_path, filename)\n",
        "            images.append({'image_path': image_path, 'label': label})\n",
        "    return pd.DataFrame(images)\n",
        "\n",
        "# Load data from directories\n",
        "lumpy_df = load_images_labels(lumpy_dir_path, 'Lumpy')\n",
        "healthy_df = load_images_labels(healthy_dir_path, 'Healthy')\n",
        "\n",
        "# Concatenate the two DataFrames into one\n",
        "combined_df = pd.concat([lumpy_df, healthy_df]).reset_index(drop=True)\n",
        "\n",
        "print(combined_df)\n",
        "print(lumpy_df)\n",
        "print(healthy_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NK6VHRkKbpfm",
        "outputId": "19e795b1-89dd-4d4c-a928-5e9cb993df15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             image_path    label  \\\n",
            "0     /content/drive/MyDrive/Lumpy_Skin_Disease/Data...    Lumpy   \n",
            "1     /content/drive/MyDrive/Lumpy_Skin_Disease/Data...    Lumpy   \n",
            "2     /content/drive/MyDrive/Lumpy_Skin_Disease/Data...    Lumpy   \n",
            "3     /content/drive/MyDrive/Lumpy_Skin_Disease/Data...    Lumpy   \n",
            "4     /content/drive/MyDrive/Lumpy_Skin_Disease/Data...    Lumpy   \n",
            "...                                                 ...      ...   \n",
            "1138  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy   \n",
            "1139  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy   \n",
            "1140  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy   \n",
            "1141  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy   \n",
            "1142  /content/drive/MyDrive/Lumpy_Skin_Disease/Data...  Healthy   \n",
            "\n",
            "                                     preprocessed_image  \n",
            "0     [[[235, 251, 239], [210, 234, 217], [218, 242,...  \n",
            "1     [[[246, 221, 197], [227, 203, 179], [239, 220,...  \n",
            "2     [[[77, 130, 227], [76, 129, 226], [77, 130, 22...  \n",
            "3     [[[153, 134, 128], [151, 133, 125], [157, 139,...  \n",
            "4     [[[255, 255, 254], [255, 254, 252], [254, 252,...  \n",
            "...                                                 ...  \n",
            "1138  [[[165, 165, 179], [166, 166, 180], [166, 166,...  \n",
            "1139  [[[75, 74, 76], [75, 75, 75], [92, 93, 97], [8...  \n",
            "1140  [[[41, 42, 52], [24, 27, 31], [21, 29, 29], [2...  \n",
            "1141  [[[79, 77, 82], [75, 74, 76], [88, 87, 89], [7...  \n",
            "1142  [[[50, 51, 55], [42, 44, 52], [38, 40, 49], [4...  \n",
            "\n",
            "[1143 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Function to read and preprocess an image\n",
        "def load_and_preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        # Adjust this section based on your preprocessing requirements:\n",
        "        # Cropping, resizing, normalization, etc.\n",
        "        image_resized = cv2.resize(image, (224, 224))  # Resize to (224, 224) for example\n",
        "        return image_resized\n",
        "    else:\n",
        "        return None  # If the image doesn't load correctly\n",
        "\n",
        "# Applying the preprocessing function to all image paths\n",
        "combined_df['preprocessed_image'] = combined_df['image_path'].apply(load_and_preprocess_image)\n",
        "\n",
        "print(combined_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4XC4FArBb1aV"
      },
      "outputs": [],
      "source": [
        "#Converting the images to numpy arrays and extracting the labels\n",
        "images = np.array(combined_df['preprocessed_image'].tolist())\n",
        "labels = combined_df['label'].map({'Lumpy': 1, 'Healthy': 0}).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2CWJKnnobdpB",
        "outputId": "d6b03604-8df3-41b3-b3f3-15794f3927bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "29/29 [==============================] - 75s 3s/step - loss: 8.8219 - accuracy: 0.5733 - val_loss: 1.2200 - val_accuracy: 0.4367\n",
            "Epoch 2/50\n",
            "29/29 [==============================] - 69s 2s/step - loss: 0.5799 - accuracy: 0.7177 - val_loss: 0.4629 - val_accuracy: 0.7948\n",
            "Epoch 3/50\n",
            "29/29 [==============================] - 68s 2s/step - loss: 0.3178 - accuracy: 0.8862 - val_loss: 0.4259 - val_accuracy: 0.8734\n",
            "Epoch 4/50\n",
            "29/29 [==============================] - 79s 3s/step - loss: 0.1710 - accuracy: 0.9628 - val_loss: 0.4648 - val_accuracy: 0.8384\n",
            "Epoch 5/50\n",
            "29/29 [==============================] - 71s 2s/step - loss: 0.1056 - accuracy: 0.9781 - val_loss: 0.4849 - val_accuracy: 0.8428\n",
            "Epoch 6/50\n",
            "29/29 [==============================] - 75s 3s/step - loss: 0.0697 - accuracy: 0.9902 - val_loss: 0.4686 - val_accuracy: 0.8559\n",
            "Epoch 7/50\n",
            "29/29 [==============================] - 71s 2s/step - loss: 0.0444 - accuracy: 0.9934 - val_loss: 0.5792 - val_accuracy: 0.8384\n",
            "Epoch 8/50\n",
            "29/29 [==============================] - 68s 2s/step - loss: 0.0379 - accuracy: 0.9956 - val_loss: 0.5441 - val_accuracy: 0.8297\n",
            "Epoch 9/50\n",
            "29/29 [==============================] - 76s 3s/step - loss: 0.0281 - accuracy: 0.9967 - val_loss: 0.5543 - val_accuracy: 0.8428\n",
            "Epoch 10/50\n",
            "29/29 [==============================] - 68s 2s/step - loss: 0.0264 - accuracy: 0.9978 - val_loss: 0.6304 - val_accuracy: 0.8079\n",
            "Epoch 11/50\n",
            "29/29 [==============================] - 81s 3s/step - loss: 0.0282 - accuracy: 0.9967 - val_loss: 0.5238 - val_accuracy: 0.8472\n",
            "Epoch 12/50\n",
            "29/29 [==============================] - 71s 2s/step - loss: 0.0212 - accuracy: 0.9978 - val_loss: 0.6580 - val_accuracy: 0.8253\n",
            "Epoch 13/50\n",
            "29/29 [==============================] - 69s 2s/step - loss: 0.0195 - accuracy: 0.9978 - val_loss: 0.5707 - val_accuracy: 0.8428\n",
            "Epoch 14/50\n",
            "29/29 [==============================] - 74s 3s/step - loss: 0.0280 - accuracy: 0.9956 - val_loss: 0.5425 - val_accuracy: 0.8428\n",
            "Epoch 15/50\n",
            "29/29 [==============================] - 75s 3s/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.5748 - val_accuracy: 0.8472\n",
            "Epoch 16/50\n",
            "29/29 [==============================] - 73s 3s/step - loss: 0.0178 - accuracy: 0.9967 - val_loss: 0.6025 - val_accuracy: 0.8515\n",
            "Epoch 17/50\n",
            "29/29 [==============================] - 73s 2s/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 0.5806 - val_accuracy: 0.8559\n",
            "Epoch 18/50\n",
            "29/29 [==============================] - 71s 2s/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.5665 - val_accuracy: 0.8515\n",
            "Epoch 19/50\n",
            "29/29 [==============================] - 80s 3s/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.5529 - val_accuracy: 0.8603\n",
            "Epoch 20/50\n",
            "29/29 [==============================] - 69s 2s/step - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.6943 - val_accuracy: 0.8341\n",
            "Epoch 21/50\n",
            "29/29 [==============================] - 70s 2s/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 0.5740 - val_accuracy: 0.8603\n",
            "Epoch 22/50\n",
            "29/29 [==============================] - 67s 2s/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 0.6884 - val_accuracy: 0.7991\n",
            "Epoch 23/50\n",
            "17/29 [================>.............] - ETA: 25s - loss: 0.0037 - accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "# Spliting the dataset into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Defining the CNN architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Converting data to a format suitable for training\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Using ImageDataGenerator flow method for the training set\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
        "\n",
        "# Using ImageDataGenerator flow method for the validation set\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=32)\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "model.summary()\n",
        "# Saving the model\n",
        "model.save('/content/drive/MyDrive/Lumpy_Skin_Disease/model.h5')\n",
        "\n",
        "# Evaluating the model\n",
        "evaluation = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {evaluation[0]}, Validation Accuracy: {evaluation[1]}\")\n",
        "\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJPajimRRV4j"
      },
      "outputs": [],
      "source": [
        "  from sklearn.metrics import confusion_matrix\n",
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "\n",
        "  # Assuming val_generator from your provided code is used for validation\n",
        "  # Predicting labels for all images in the validation set\n",
        "  predictions = model.predict(val_generator)\n",
        "  predicted_labels = (predictions > 0.5).astype(int)\n",
        "\n",
        "  # Get true labels from the validation generator\n",
        "  true_labels = y_val\n",
        "\n",
        "  # Computing the confusion matrix\n",
        "  cm = confusion_matrix(true_labels, predicted_labels.flatten())\n",
        "\n",
        "  # Printing the confusion matrix\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(cm)\n",
        "\n",
        "  # Optionally, visualize the confusion matrix\n",
        "  plt.figure(figsize=(4,4))\n",
        "  sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=['Healthy', 'Lumpy'], yticklabels=['Healthy', 'Lumpy'])\n",
        "  plt.xlabel('Predicted Labels')\n",
        "  plt.ylabel('True Labels')\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGKZhzW4vvAa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loading the model\n",
        "model_path = '/content/drive/MyDrive/Lumpy_Skin_Disease/model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "def predict_disease(image_path):\n",
        "    # Loading the image file\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for matplotlib\n",
        "\n",
        "    # Preprocessing the image - Ensuring this matches the preprocessing used in training\n",
        "    img_preprocessed = cv2.resize(img, (224, 224))  # Resizing the image to 224x224 pixels\n",
        "    img_preprocessed = img_preprocessed / 255.0  # Normalizing pixel values to [0, 1]\n",
        "    img_preprocessed = np.expand_dims(img_preprocessed, axis=0)\n",
        "\n",
        "    # Predicting the class of the image\n",
        "    prediction = model.predict(img_preprocessed)\n",
        "\n",
        "    # Determine the predicted class\n",
        "    predicted_class = 'Lumpy' if prediction[0][0] > 0.5 else 'Healthy'\n",
        "\n",
        "    # Display the image and the prediction\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.title(f'Prediction: {predicted_class} - Confidence: {prediction[0][0]:.2f}')\n",
        "    plt.show()\n",
        "\n",
        "    return predicted_class, prediction[0][0]\n",
        "\n",
        "# Assuming the user uploads an image and the path is stored in `user_uploaded_image_path`\n",
        "user_uploaded_image_path = '/content/download (2).jpeg'\n",
        "predicted_class, confidence = predict_disease(user_uploaded_image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QyOzAZiKtzj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MEM1UJbwepu"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}